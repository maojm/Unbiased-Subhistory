\documentclass[11pt,letterpaper]{article}

\usepackage{fullpage,times}

% a very useful package for edits and comments, from David Kempe (USC)
\usepackage{color-edits}
%\usepackage[suppress]{color-edits}  % use this to suppress the package
%\addauthor{ab}{green}   % ab for Ashwin
%\addauthor{bk}{magenta} % bk for Bobby
\addauthor{as}{red}      % as for Alex
%\addauthor{mb}{blue}    % mb for Moshe
% e.g. for Alex, provides \asedit{}, \ascomment{} and \asdelete{}.

\begin{document}
%\vspace{-30mm}

\section*{Summary: Incentivizing Exploration with Unbiased Histories}


In a social learning setting, there is a set of actions, each of which has a fixed but unknown expected payoff. Agents arrive one by one, each chooses an action with the goal of maximizing the payoff.  A disclosure policy tries to coordinate the choices of the agents by sending messages about the history of past actions. The goal of the disclosure policy is to minimize the regret of the action sequence chosen by the agents. Prior work achieves much progress with disclosure policies that merely recommend an action to each user. (Absent agents' incentives, such policy is a multi-armed bandit algorithm.) However, all this work relies heavily on trust and rationality assumptions, standard in economic theory, yet quite problematic in the context of the motivating applications. However, all this work relies heavily on trust and rationality assumptions, standard in economic theory, yet quite problematic in the context of the motivating applications.

In this paper, we design disclosure policies which incentivize good performance under more plausible behavioral assumptions. Conceptually, we would like to retain the trustworthiness of revealing the full history, while avoiding the herding behavior induced by such disclosure policy (which may lead to regret linear in the time horizon). We focus on messages, called {\em unbiased subhistories}, consisting of the actions and rewards from a subsequence of past agents, where the subsequence is chosen ahead of time. We further require these messages to be \emph{transitive}: if a message includes action and reward from a particular agent, then it also includes the message sent to that agent. We posit a flexible model of agent response, which we argue is plausible for this class of disclosure policies. Our main result is a disclosure policy using unbiased, transitive subhistories that obtains regret $\tilde{O}(\sqrt{T})$, where $T$ is the time horizon.  We also exhibit simpler policies with higher, but still sublinear, regret.  These policies can be interpreted as dividing a sublinear number of agents into constant-sized focus groups, whose histories are then fed to future agents.


\end{document}
